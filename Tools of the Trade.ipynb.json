{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tools of the Trade.ipynb","version":"0.3.2","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dE5QmKuOROJA","colab_type":"text"},"source":["# Introduction to TensorFlow: the Estimator API\n","\n","In this tutorial we will use the **scipy** ecosystem to preprocess data, then **scikit-learn** and TensorFlow's **canned estimators** to do machine learning.\n","\n","The sample data are [spectrograms](https://en.wikipedia.org/wiki/Spectrogram) of phonemes (smallest unit of meaningful sound in speech). We'll attempt to cluster them based on the similarity of their time series, and also classify them correctly.\n","\n","\n","### 0. Loading the data with ``numpy`` and ``pandas``\n","No data, no ML.\n","\n","### 1. Unsupervised: Spectral Clustering with ``scipy`` and ``sklearn``\n","First, we will define a correlation score between phonemes, and use spectral clustering to find groups of phonemes that correlate well together.\n","\n","### 2. Supervised: Recurrent Neural Network with ``tf.estimator``\n","Next, we'll use the full spectrogram to predict the phoneme as a categorical label."]},{"cell_type":"markdown","metadata":{"id":"hlt_DxuztuIA","colab_type":"text"},"source":["# 0. Loading the data\n","\n","Before you start executing code, make sure you have added this notebook and the two data files provided in the shared Google Drive folder to your Drive and are using your **own copy of this notebook**.\n","\n","First, import some scientific packages..."]},{"cell_type":"code","metadata":{"id":"uR1Aig6RVBJr","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","# NOT INTERESTING (parsing function)\n","from ast import literal_eval"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l-7XyZswAu4J","colab_type":"text"},"source":["Next, mount \"My Drive\" into Colab so the runtime can access the files. If you hadn't already added the datafiles to \"My Drive\" before mounting, you'll need to `force_remount` once they're copied across."]},{"cell_type":"code","metadata":{"id":"42hu1TQECLc_","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","\n","drive.mount('/gdrive')\n","#drive.mount('/gdrive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f6P-t0SSFMaG","colab_type":"code","colab":{}},"source":["PATH_TO_DATA='/gdrive/My Drive/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hulpqTEcXJga","colab_type":"code","colab":{}},"source":["# NOT INTERESTING (it defines a conversion from string '[[x,x,x],[x,x,x]]' to a numpy array)\n","converters = {'spectrogram': lambda x:np.array(literal_eval(x), dtype=np.float32).T}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"61qy8-J8shcS","colab_type":"text"},"source":["### Reading the data into a pandas dataframe\n","\n","The following cell reads from file into a Python object called a dataframe. Dataframes allow us to manage structured data intuitively and to perform basic transformations with relative ease.\n","\n","The load operation might take ~20s."]},{"cell_type":"code","metadata":{"id":"PFu-6fwzvzCT","colab_type":"code","colab":{}},"source":["phoneme_train = pd.read_csv(PATH_TO_DATA+'phoneme_train.csv', converters=converters)\n","phoneme_test = pd.read_csv(PATH_TO_DATA+'phoneme_test.csv', converters=converters)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I7RST3Jjw2VK","colab_type":"text"},"source":["Looking at the first 5 rows of the dataframe, it's a two-column dataset with each row containing a spectrogram (an array of shape (217, 11)) – and a text label saying what phoneme it is (the first 5 are all '[AA](https://en.wikipedia.org/wiki/Open_back_unrounded_vowel)')."]},{"cell_type":"code","metadata":{"id":"ZU6oNcrgw1Ss","colab_type":"code","colab":{}},"source":["# NOT INTERESTING (save the shape and size of a spectrogram)\n","spec_shape = phoneme_train.spectrogram[0].shape\n","spec_size = phoneme_train.spectrogram[0].size\n","\n","# NOT INTERESTING (save the overall mean and standard deviation per band)\n","channel_means = np.stack(phoneme_train.spectrogram.tolist()).mean(axis=(0,1))\n","channel_stds = np.stack(phoneme_train.spectrogram.tolist()).std(axis=(0,1))\n","\n","print(spec_shape)\n","phoneme_train.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I41GKxk7wOrE","colab_type":"text"},"source":["A quick inspection of the different phonemes reveals that the train set contains 85 examples of each:"]},{"cell_type":"code","metadata":{"id":"QthQvTEuJrYM","colab_type":"code","colab":{}},"source":["phonemes = phoneme_train.phoneme.unique()\n","phoneme_train.phoneme.value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4jh-jECXzCdX","colab_type":"text"},"source":["Each spectrogram has 11 bands, so 11 lines are plotted when we plot a single example:"]},{"cell_type":"code","metadata":{"id":"IAbOzduDN8ik","colab_type":"code","colab":{}},"source":["# Have a look at one of the sequences\n","INDEX = 0\n","\n","# PATCH 2019-05-24 (insert import)\n","import matplotlib.pyplot as plt\n","\n","# NOT INTERESTING (plotting)\n","# PATCH 2019-05-24 (remove 'sns.')\n","plt.imshow(phoneme_train.spectrogram[INDEX].T, aspect=8)\n","plt.grid(False)\n","plt.title('Spectrogram for one example of phoneme \"{}\"'.format(phoneme_train.phoneme[INDEX]))\n","plt.xlabel('time')\n","plt.ylabel('frequency band')\n","plt.ylim([11,1])\n","plt.yticks([x for x in range(11)])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7s-Jp6Ayoh5Z","colab_type":"text"},"source":["# 1. Unsupervised: Spectral Clustering\n","\n","Moving on to more interesting work, we'll use a signal processing function from scipy to define similarity between two spectrograms.\n","\n","First import the cross-correlation function:"]},{"cell_type":"code","metadata":{"id":"NkBVMShHLyW4","colab_type":"code","colab":{}},"source":["from scipy.signal import correlate\n","\n","# downsample the dataset to reduce computation time\n","subset = phoneme_train.sample(frac=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"58W54e9zuU78","colab_type":"text"},"source":["### Feel free to ignore this cell (details of obtaining phoneme similarity scores)\n","\n","\n","The **cross-correlation** between two time series is a measure of how alike they are for each possible time offset. Traces that are identical will have a maximum correlation of **1** (at offset=0); a minimum correlation of **-1** indicates one is an upside-down version of the other. Here we iterate through all the pairs of spectrograms and use the **average maximum correlation** seen between each pair of phonemes as a similarity measure."]},{"cell_type":"code","metadata":{"id":"UHRVAJWlnCu4","colab_type":"code","colab":{}},"source":["# NOT INTERESTING (initialize an empty correlation matrix)\n","corr = pd.DataFrame(np.zeros([len(phonemes),len(phonemes)]),\n","                    index=phonemes,\n","                    columns=phonemes)\n","counts = pd.DataFrame(np.zeros([len(phonemes),len(phonemes)]),\n","                    index=phonemes,\n","                    columns=phonemes)\n","\n","\n","# Nested loops to get every pair of *spectrograms*\n","for i in range(len(subset)-1):\n","  phon1 = subset.phoneme.iloc[i]\n","  spec1 = subset.spectrogram.iloc[i]\n","  spec1 = (spec1-spec1.mean(axis=0))/spec1.std(axis=0) # normalize\n","  \n","  for j in range (i+1,len(subset)):\n","    phon2 = subset.phoneme.iloc[j]\n","    spec2 = subset.spectrogram.iloc[j]\n","    spec2 = (spec2-spec2.mean(axis=0))/spec2.std(axis=0) # normalize\n","    \n","    # Get the maximum cross-correlation for this pair\n","    c = correlate(spec1, spec2).max()/spec_size\n","    \n","    # record this value as an example of the appropriate **phoneme** pair\n","    if not np.isnan(c):\n","      corr.at[phon1,phon2] += c\n","      corr.at[phon2,phon1] += c\n","\n","      counts.at[phon1,phon2] += 1\n","      counts.at[phon2,phon1] += 1\n","\n","\n","# Get the average correlation value per **phoneme** pair\n","corr /= counts"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sh0n5Ys127Xy","colab_type":"text"},"source":["The resulting correlation matrix looks like this:"]},{"cell_type":"code","metadata":{"id":"vZwfyb68oA7o","colab_type":"code","colab":{}},"source":["sns.heatmap(corr, square=True)\n","plt.title('matrix of averaged maximum correlation')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WXlcoOzdv_-t","colab_type":"text"},"source":["### Spectral Clustering\n","\n","Spectral clustering is a **distance-based clustering** method. Given a distance function (or kernel) between any pair of examples, the algorithm seeks to form clusters whose members are all near to each other.\n","\n","Here we'll use the cross-correlation directly as a similarity metric.\n","\n","Training this algorithm is as simple as making a clusterer with the desired number of clusters, then passing the correlation data to its `fit_predict()` method."]},{"cell_type":"code","metadata":{"id":"2c9pnHm2WF6F","colab_type":"code","colab":{}},"source":["from sklearn.cluster import SpectralClustering\n","\n","\n","N_CLUSTERS = 3\n","\n","clusterer = SpectralClustering(n_clusters=N_CLUSTERS,\n","                               affinity='precomputed', # precomputed because we already have the similarity matrix\n","                               n_init=1000) # use the best result from 1000 random starting positions\n","\n","cluster_labels = clusterer.fit_predict(corr)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2oxV7y761Hq1","colab_type":"text"},"source":["**Scikit-learn** provides very good integration with native python, `numpy` and `pandas` data structures. However, it is a \"**library**\" rather than a \"framework\" for machine learning – many 'classic' ML algorithms are implemented, but with limited customizability.\n","\n","Let's feed the cluster ids back into the original correlation matrix and see what the results look like:"]},{"cell_type":"code","metadata":{"id":"SZSLNqmBWf_R","colab_type":"code","cellView":"both","colab":{}},"source":["# NOT INTERESTING (helps to plot clusters)\n","from sympy import prime\n","\n","\n","# NOT INTERESTING (function to sort rows into clusters)\n","def sort_into_clusters(d, cluster_labels):\n","  d_with_labels = d.assign(cluster=cluster_labels)\n","  d_sorted = d_with_labels.sort_values('cluster', axis=0)\n","  labels = d_sorted.pop('cluster')\n","  labels = labels.map(lambda x: prime(x+1)) # make cluster ids prime\n","  labels = labels.values.reshape((-1,1))\n","  \n","  return d_sorted, labels\n","\n","\n","# NOT INTERESTING (sort correlation matrix into clusters)\n","corr_sorted, row_labels = sort_into_clusters(corr, cluster_labels)\n","corrT_sorted, col_labels = sort_into_clusters(corr_sorted.T, cluster_labels)\n","\n","\n","# NOT INTERESTING (plot the reordered correlation matrix)\n","sns.heatmap(corrT_sorted, square=True)\n","plt.title('clustered correlation matrix')\n","plt.show()\n","\n","# NOT INTERESTING (plot the clusters)\n","cluster = row_labels.dot(col_labels.T)\n","sns.heatmap(cluster**0.5%1 == 0, square=True, cbar=False,\n","            xticklabels=corrT_sorted.index.values,\n","            yticklabels=corrT_sorted.index.values) # colour black when the product of the prime cluster ids is a perfect square\n","plt.title('cluster boundaries')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQrIjoTl77Bc","colab_type":"text"},"source":["### Results\n","\n","When asked to find three clusters, the algorithm splits the phonemes pretty cleanly into vowels, voiceless consonants and voiced consonants. Not bad!"]},{"cell_type":"markdown","metadata":{"id":"CsSubvUAir-b","colab_type":"text"},"source":["# 2. Supervised: Recurrent Neural Network\n","\n","We now want to try and predict the phoneme type (vowel, voiceless consonant or voiced consonant) from the spectrogram. We'll train with the data in phoneme_train, and see how the model performs on phoneme_test.\n","\n","First we import TensorFlow:"]},{"cell_type":"code","metadata":{"id":"kv4qA69-jCvS","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","tf.logging.set_verbosity(tf.logging.WARN)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_2KYcVGovVl","colab_type":"code","colab":{}},"source":["# NOT INTERESTING (check what TensorFlow version is being used)\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DL1q69Sv8jqT","colab_type":"text"},"source":["### feature_column\n","\n","TensorFlow has a useful class in its high-level API called a **feature column**. This is a container for input features, which defines their datatypes and performs essential preprocessing (e.g. normalizing, one-hot encoding, embedding) so that the full model is fully defined before data is fed in.\n","\n","Here we're using a `sequence_numeric_column` from `tf.contrib` and feeding that into a recurrent neural network (also from `tf.contrib`)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"63b5qUQmIqNf","colab":{}},"source":["# make one input column (for the spectrogram)\n","seq_col = tf.contrib.feature_column.sequence_numeric_column('spectrogram')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-LRjr1uV-13s","colab_type":"code","colab":{}},"source":["# define a class label from a phoneme label\n","def phoneme_to_class(phoneme):\n","  if phoneme[0] in ['A','E','I','O','U']:\n","    return 'vowel'\n","  elif phoneme in ['S','SH','T','F','TH','CH','K','HH','P']:\n","    return 'voiceless'\n","  else:\n","    return 'voiced'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bqZ-LWsB-jwk","colab_type":"text"},"source":["### estimator\n","\n","Next we make the RNNClassifier estimator.\n","\n","In the arguments, we select 2 Gated Recurrent Unit layers of 64 and 32 hidden units respectively, and give a filepath for storing the model once trained."]},{"cell_type":"code","metadata":{"id":"W3yOq1jnWRk2","colab_type":"code","colab":{}},"source":["# make the model\n","estimator = tf.contrib.estimator.RNNClassifier(\n","    [seq_col],\n","    num_units=[64,32],\n","    cell_type='gru',\n","    model_dir='./RNNmodel',\n","    n_classes=3,\n","    label_vocabulary=['vowel','voiceless','voiced'],\n","    weight_column='weight'\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qNZLqmoI-Dup","colab_type":"text"},"source":["The **feature column** and the **estimator** together define the empty model from input values to output values. Now it just needs some training data.\n","\n","`get_examples` will turn a pandas dataframe into feature and label tensors for a TensorFlow model. Feel free to ignore what's going on inside."]},{"cell_type":"code","metadata":{"id":"noox51c181jZ","colab_type":"code","colab":{}},"source":["# define how to normalize the input data\n","normalize = lambda x:(x-channel_means)/channel_stds\n","\n","# define how to feed data to the estimator\n","def get_examples(data, shuffle=False, epochs=None):\n","  \n","  # retrieve the features and labels from the data\n","  features = np.stack(data.spectrogram.tolist())\n","  features = normalize(features)\n","  labels = data.phoneme.apply(phoneme_to_class)\n","  \n","  # boost weight of unvoiced class to match the other two \n","  weights = labels.apply(lambda y: 15/9 if y =='voiceless' else 1)\n","  \n","  # NOT INTERESTING (use the tf.data API to shuffle the dataset every epoch)\n","  dataset = tf.data.Dataset.from_tensor_slices((features, labels, weights))\n","  if shuffle: dataset = dataset.shuffle(len(data))\n","  dataset = dataset.batch(len(data))\n","  iterator = dataset.repeat(epochs).make_one_shot_iterator()\n","  \n","  batch, labels, weights = iterator.get_next()\n","  \n","  # NOT INTERESTING (SparseTensor expected for RNN model, since it also accepts categorical input)\n","  indices = tf.constant([[i,x,y]\n","                         for i in range(len(data))\n","                         for x in range(features.shape[1])\n","                         for y in range(features.shape[2])],\n","                        dtype=tf.int64) # every index\n","  values = tf.reshape(batch, [features.size])\n","  \n","  features = tf.SparseTensor(indices, values, features.shape)\n","  \n","  return {'spectrogram':features, 'weight':weights}, labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P8xeov2iAN1J","colab_type":"text"},"source":["### input_fn\n","\n","The input functions below will be passed to the estimator's `train()` and `predict()` methods: they define how exactly to feed the model with features and labels from the pandas dataframe.\n","\n"]},{"cell_type":"code","metadata":{"id":"eBAA1NRi5Poo","colab_type":"code","colab":{}},"source":["def train_input_fn():\n","  features, labels = get_examples(phoneme_train, shuffle=True)  \n","  return features, labels\n","\n","\n","def predict_input_fn():\n","  features, labels = get_examples(phoneme_test, epochs=1)  \n","  return features, labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GymYoRWV-dWt","colab_type":"text"},"source":["### train\n","\n","Training this neural network for 10 steps does take some time (~10 mins)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"z0XaVpOhIqrJ","colab":{}},"source":["estimator = estimator.train(train_input_fn, steps=10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oO_b9RlMCiyK","colab_type":"text"},"source":["After training, the model has been saved in the location specified when creating the estimator. The contents of this directory are:\n","\n","*   `checkpoint` – records metadata of the training checkpoint to load when continuing or predicting\n","*   `graph.pbtxt` – definition of the mathematical operations for forward (inference) and backward (training) model execution.\n","*  `model.ckpt-*.*` – contain the stored numerical weights and metadata of a model at a particular point in training.\n","* `events.out.*` – logging\n","\n"]},{"cell_type":"code","metadata":{"id":"z17PJ8MBOyEh","colab_type":"code","colab":{}},"source":["!ls ./RNNmodel"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M3z3pHyk1hnT","colab_type":"text"},"source":["## Evaluating performance\n","\n","Now that the model has trained, let's see what it predicts for the test set."]},{"cell_type":"code","metadata":{"id":"9D-MKhC2Sv0q","colab_type":"code","colab":{}},"source":["# generate predictions and store them in a DataFrame\n","predictions = estimator.predict(predict_input_fn, predict_keys=['classes'])\n","results = pd.DataFrame(predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XCAIAPmXgkO","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix\n","\n","confusion = confusion_matrix(phoneme_test.phoneme.apply(phoneme_to_class),\n","                             results.applymap(lambda x:x[0].decode('utf-8')),\n","                             labels=['vowel','voiceless','voiced'])\n","\n","confusion = pd.DataFrame(data=confusion,\n","                         index=['vowel','voiceless','voiced'],\n","                         columns=['vowel','voiceless','voiced'])\n","\n","sns.heatmap(confusion, square=True)\n","plt.xlabel('predicted label')\n","plt.ylabel('true label')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QaS0V2jjbuXO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}